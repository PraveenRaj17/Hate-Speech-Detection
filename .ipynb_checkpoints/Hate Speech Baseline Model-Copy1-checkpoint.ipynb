{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c624195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "import contractions\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score ,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bea21ce",
   "metadata": {},
   "source": [
    "# DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9652d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('labeled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f440a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c739ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8644d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename column names which are displaced by row\n",
    "df = df.rename(columns={\"Unnamed: 0\": \"Tweet ID\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b203bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the Columns with NAN values\n",
    "print(df.isnull().sum().sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329fadbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b1387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a5a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.memory_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc7fcec",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3aa77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Expansion of Clitics:\n",
    "#For example, Shouldn't -> Should not, I'll -> I will\n",
    "def cliticexp(sent:str):\n",
    "    exp = [contractions.fix(w) for w in sent]\n",
    "    exp_text = ''.join(exp)\n",
    "    return exp_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9ec1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizes sentences\n",
    "def sent_tokenizer(sent:str):\n",
    "    tokens = re.split(r\"[^A-Za-z0-9-']\",sent)\n",
    "    tokens = list(filter(len,tokens))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4dd188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes punctuations\n",
    "def listtostring(L:list):\n",
    "    string = \"\"\n",
    "    for l in L:\n",
    "        string = string+l.lower()+' '\n",
    "    return string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1223f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting list of tokens to lowercase string\n",
    "tokenized = []\n",
    "for i in range(len(df)):\n",
    "    tok = sent_tokenizer(df.iloc[i,6])\n",
    "    tokenized.append(listtostring(tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310e92b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac4ad1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Processed_Tweets'] = tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e55febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d87d48",
   "metadata": {},
   "source": [
    "# EXPLORATORY DATA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21acb242",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26332bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0da436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b1d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "sns.countplot(x='class',data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3480b5d5",
   "metadata": {},
   "source": [
    "# BUILDING A  BASELINE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4679053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TfidfVectorizer model and document-term matrix\n",
    "# Pre-process the documents\n",
    "def vectorize_train(training_docs):\n",
    "    tfidf_train = None\n",
    "# Initialize the TfidfVectorizer model and document-term matrix\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', ngram_range=(1,3))\n",
    "    tfidf_train = vectorizer.fit_transform(training_docs)\n",
    "    return vectorizer, tfidf_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28db935",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the vectorizer\n",
    "vectorizer, tfidf_train = vectorize_train(df['Processed_Tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b34f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(tfidf_train,df['class'],test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7074527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building a logistic regression model\n",
    "LR = LogisticRegression(C=5e1, solver='lbfgs', multi_class='multinomial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b19878e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model\n",
    "LR.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a17889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the prediction\n",
    "pred = LR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b61ef5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESULTS\n",
    "confusion = sklearn.metrics.confusion_matrix(Y_test,pred)\n",
    "accuracy = sklearn.metrics.accuracy_score(Y_test,pred)\n",
    "#precision = sklearn.metrics.precision_score(Y_test,pred)\n",
    "#recall = sklearn.metrics.recall_score(Y_test,pred)\n",
    "#F1 = (2 * precision * recall)/(precsion + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf148022",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CONFUSION MATRIX\")\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bf8bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class-wise Precision score\n",
    "ph = confusion[0,0]/ np.sum(confusion[:,0])\n",
    "poff = confusion[1,1]/ np.sum(confusion[:,1])\n",
    "pn = confusion[2,2]/ np.sum(confusion[:,2])\n",
    "print(\"Precision for Hate Tweets:\",ph)\n",
    "print(\"Precision for Offensive Tweets:\",poff)\n",
    "print(\"Precision for Neutral Tweets:\",pn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class-wise Recall/Sensitivity score\n",
    "rh = confusion[0,0]/ np.sum(confusion[0,:])\n",
    "roff = confusion[1,1]/ np.sum(confusion[1,:])\n",
    "rn = confusion[2,2]/ np.sum(confusion[2,:])\n",
    "print(\"Recall for Hate Tweets:\",rh)\n",
    "print(\"Recall for Offensive Tweets:\",roff)\n",
    "print(\"Recall for Neutral Tweets:\",rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1db993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class-wise F1 Score\n",
    "f1h = (2*ph*rh)/(ph+rh)\n",
    "f1off = (2*poff*roff)/(poff+roff)\n",
    "f1n = (2*pn*rn)/(pn+rn)\n",
    "print(\"F1 Score for Hate Tweets:\",f1h)\n",
    "print(\"F1 Score for Offensive Tweets:\",f1off)\n",
    "print(\"F1 Score for Neutral Tweets:\",f1n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72007e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class-wise Accuracy Score\n",
    "rh = confusion[0,0]/ np.sum(confusion[0,:])\n",
    "roff = confusion[1,1]/ np.sum(confusion[1,:])\n",
    "rn = confusion[2,2]/ np.sum(confusion[2,:])\n",
    "print(\"Recall for Hate Tweets:\",rh)\n",
    "print(\"Recall for Offensive Tweets:\",roff)\n",
    "print(\"Recall for Neutral Tweets:\",rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369e53a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Report\n",
    "print(sklearn.metrics.classification_report(Y_test,pred))\n",
    "print(\"Overall Accuracy =\",\"{0:.4f}\".format(accuracy*100),\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
